%NEURAL PRESY ;)

%----------------------------------------------------------------------------------------
%   PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass{beamer}

\usefonttheme{professionalfonts}
\usefonttheme[onlymath]{serif}

\mode<presentation> {

\usetheme{Berkeley}
%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm,algorithmic}

% tikz and associated macros
\usepackage{tikz}
\usepackage{tikz-cd}

\usepackage{pgfplots}
\def\layersep{2cm}
\def\nodesep{0.25cm}
\newcommand*{\Scale}[2][4]{\scalebox{#1}{$#2$}}%
\newcommand*{\Resize}[2]{\resizebox{#1}{!}{$#2$}}%
\newcommand\sep{1.9cm}
\newcommand\height{0.9cm}
\usetikzlibrary{decorations.pathmorphing, backgrounds}
\tikzset{snake it/.style={decorate, decoration=snake}}

%
%

% math
\usepackage{amsthm}

 \usepackage{relsize}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathabx}

\numberwithin{equation}{subsection}
\numberwithin{theorem}{subsection}

\DeclareSymbolFont{cmlargesymbols}{OMX}{cmex}{m}{n}
\let\sumop\relax
\DeclareMathSymbol{\sumop}{\mathop}{cmlargesymbols}{"50}


\def\reals{{\mathbb R}}
\def\torus{{\mathbb T}}
\def\integers{{\mathbb Z}}
\def\rationals{{\mathbb Q}}
\def\expect{\mathop{{\mathbb{E}}}}
\def\tens{\mathop{{\bigotimes}}}
\def\naturals{{\mathbb N}}
\def\complex{{\mathbb C}\/}
\def\distance{\operatorname{distance}\,}
\def\support{\operatorname{support}\,}
\def\dist{\operatorname{dist}\,}
\def\Span{\operatorname{span}\,}
\def\degree{\operatorname{degree}\,}
\def\kernel{\operatorname{kernel}\,}
\def\dim{\operatorname{dim}\,}
\def\codim{\operatorname{codim}}
\def\trace{\operatorname{trace\,}}
\def\dimension{\operatorname{dimension}\,}
\def\codimension{\operatorname{codimension}\,}
\def\kernel{\operatorname{Ker}}
\def\Re{\operatorname{Re\,} }
\def\Im{\operatorname{Im\,} }
\def\eps{\varepsilon}
\def\lt{L^2}
\def\bull{$\bullet$\ }
\def\det{\operatorname{det}}
\def\Det{\operatorname{Det}}
\def\diameter{\operatorname{diameter}}
\def\symdif{\,\Delta\,}
\newcommand{\norm}[1]{ \|  #1 \|}
\newcommand{\set}[1]{ \left\{ #1 \right\} }
\def\suchthat{\mathrel{}\middle|\mathrel{}}
\def\one{{\mathbf 1}}
\def\cl{\text{cl}}

\def\newbull{\medskip\noindent $\bullet$\ }
\def\nobull{\noindent$\bullet$\ }
\def\defeq{\stackrel{\text{def}}{=}}


\newcommand{\argmin}{\mathop{\mathrm{argmin}}} 
\newcommand{\argmax}{\mathop{\mathrm{argmax}}} 


\def\scriptf{{\mathcal F}}
\def\scriptq{{\mathcal Q}}
\def\scriptg{{\mathcal G}}
\def\scriptm{{\mathcal M}}
\def\scriptb{{\mathcal B}}
\def\scriptc{{\mathcal C}}
\def\scriptt{{\mathcal T}}
\def\scripti{{\mathcal I}}
\def\scripte{{\mathcal E}}
\def\scriptv{{\mathcal V}}
\def\scriptw{{\mathcal W}}
\def\scriptu{{\mathcal U}}
\def\scriptS{{\mathcal S}}
\def\scripta{{\mathcal A}}
\def\scriptr{{\mathcal R}}
\def\scripto{{\mathcal O}}
\def\scripth{{\mathcal H}}
\def\scriptd{{\mathcal D}}
\def\scriptl{{\mathcal L}}
\def\scriptn{{\mathcal N}}
\def\scriptp{{\mathcal P}}
\def\scriptk{{\mathcal K}}
\def\scriptP{{\mathcal P}}
\def\scriptj{{\mathcal J}}
\def\scriptz{{\mathcal Z}}
\def\scripts{{\mathcal S}}
\def\scriptx{{\mathcal X}}
\def\scripty{{\mathcal Y}}
\def\frakv{{\mathfrak V}}
\def\frakG{{\mathfrak G}}
\def\frakB{{\mathfrak B}}
\def\frakC{{\mathfrak C}}
\def\ugearrow{{
  \mathlarger{
    \mathlarger{
      \mathlarger{
        \mathlarger{
          \mathlarger{
            \mathlarger{
              \mathlarger{
              \mathlarger{\implies}
              }
            }
          }
        }
      }
    }
  }
}}



%----------------------------------------------------------------------------------------
%   TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Reinforcement Learning]{Bootcamp 6: Reinforcement Learning}

\author[Guss \& Bartlett]{\includegraphics[height=2cm,width=2cm]{BlueGold_fill_small.png}\\   William H. Guss, James Bartlett\\\{wguss, james\}@ml.berkeley.edu\\Machine Learning at Berkeley}
\date{April 22, 2016} % Date, can be changed to a custom date
\makeatletter
\newcommand{\verbatimfont}[1]{\renewcommand{\verbatim@font}{\ttfamily#1}}
\makeatother

\usefonttheme{professionalfonts}

\begin{document}
  

\begin{frame}{}
\titlepage
\end{frame}


\addtobeamertemplate{frametitle}{}{%
\begin{tikzpicture}[remember picture,overlay]
\node[anchor=north east,yshift=10pt] at (current page.north east) {\includegraphics[height=2cm]{White_outline_small_name_transparent.png}};
\end{tikzpicture}}

\begin{frame}

\frametitle{Overview}
\tableofcontents
\end{frame}


%----------------------------------------------------------------------------------------
%   PRESENTATION SLIDES
%----------------------------------------------------------------------------------------
\section{Introduction}
\include{sections/introduction}

\section{Theory}
\include{sections/background}


\section{Algorithms}
\begin{frame}
\frametitle{$\ $}
  \begin{center}
    \Huge{\textbf{Algorithms}}
  \end{center}
\end{frame}


\input{sections/bh}



\begin{frame}
\frametitle{Q-Learning (State-action Value Iteration)}
  \textbf{The action-value function (simplified).}
  \begin{enumerate}
    \item  The future expected reward of an agent $\pi$ is
    \begin{equation*}
      Q^\pi(s_t, a_t) = \underbrace{r(s_t, a_t)}_{\text{reward for } a_t} + \sum_{n={t+1}}^\infty \gamma^n r(s_n, \pi(s_n))
    \end{equation*}
    \item The Bellman equation gives us 
    \begin{equation*}
      Q^\pi(s_t, a_t) = r_t + \gamma Q^\pi(s_{t+1}, \pi(s_{t+1}))
    \end{equation*}`'
    \item Given some state $s_t$, the \textbf{best} agent, $\pi^*$ is one that take action 
    \begin{equation*}
      a_t = \arg \max_a Q(s_t, a).   
    \end{equation*}
  \end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Q-Learning (State-action Value Iteration)}
\textbf{TODO: DO THESE SLIDES}
  \textbf{The action-value function (simplified).}
  \begin{enumerate}
    \item The $Q$ function for $\pi^*$ is
    \begin{equation*}
      Q^*(s_t, a_t) = r_t + \gamma \arg \max_a Q^\pi(s_{t+1}, a).
    \end{equation*}
    \item We can \emph{approximate} this with deep learning!
    \begin{enumerate}
      \item Make a neural network $\scriptn: \scripts \to \mathbb{R}^n$ which predicts 
      the future reward of taking each possible action
      \begin{equation*}
        \scriptn(s_t) =\begin{pmatrix}
            Q^*(s_t, a_1) \\
             Q^*(s_t, a_2)\\
             \vdots \\
              Q^*(s_t, a_n)
        \end{pmatrix}
      \end{equation*}
    \end{enumerate}
  \end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Q-Learning (State-action Value Iteration)}
  \textbf{Deep Q-Learning}
\begin{center}
  \begin{tikzpicture}
\node[rectangle] at (0,0) {$s_t$};
\node[rectangle] at (1.5,0) [draw,thick,minimum width=1cm,minimum height=2cm] (B) {$\scriptn$};
\node[rectangle] at (4.4, 2)  [draw, fill=red!30] (C1) {$Q^*(s_t,a_1) = -12$};
\node[rectangle] at (4.4, 1)  [draw, fill=red!30] (C2) {$Q^*(s_t,a_2) = 0.17$};
\node[rectangle] at (4.4, 0)  [draw, fill=green!30] (C3) {$Q^*(s_t,a_3) = 0.22$};
\node[rectangle] at (4.4, -1) [draw, fill=red!30]  (C4) {$Q^*(s_t,a_4) = 0.03$};
\node[rectangle] at (4.4, -2) [draw, fill=red!30]  (C5) {$Q^*(s_t,a_5) = -3.2$};
\node[rectangle] at (8.2, 0) (D) {$ \pi(s_t) =  \arg \max_a \scriptn(s_t)$};
\draw[->] (0,0) edge (B);
\draw[->] (B) edge (C1.west);
\draw[->] (B) edge (C2.west);
\draw[->] (B) edge (C3.west);
\draw[->] (B) edge (C4.west);
\draw[->] (B) edge (C5.west);
\end{tikzpicture} 
\end{center}
\end{frame}


\begin{frame}
  \frametitle{Policy Iteration}
  \textbf{Deep Determisitic Policy Gradient}
  \begin{enumerate}
    \item Actor neural network $\mu: \scripts \to \scripta$
    \item Critic network $Q^\mu: \scripts \times \scripta \to \mathbb{R}$
    \item Performance of $\mu$ is $Q^\mu(s_t, \mu(s_t))$. \textbf{Maximize performance!} $\nabla_W Q^{\mu}(s_t, a_t) = \nabla_a Q^\mu(s_t,a) \cdot \nabla_W \mu(s_t)$
  \end{enumerate}
\begin{center}
  \begin{tikzpicture}
\node[rectangle] at (0,0)  {$s_t$};
\node[rectangle] at (1.75,0) [draw,thick,minimum width=0.2cm,minimum height=1.8cm, fill=black] (BC1) {};
\node[rectangle] at (2.25,0) [draw,thick,minimum width=0.2cm,minimum height=1.8cm, fill=black] (BC2) {};
\node[rectangle] at (1.5,0) [draw,thick,minimum width=0.3cm,minimum height=2cm] (B1) {};
\node[rectangle] at (2,0) [draw,thick,minimum width=0.3cm,minimum height=2cm] (B2) {};
\node[rectangle] at (2.5,0) [draw,thick,minimum width=0.3cm,minimum height=2cm] (B3) {};
\node[rectangle] at (3.5,0) (action) {$a_t$};
\draw[->] (B3.east) edge (action.west);
\node[rectangle] at  (B2.north) {$\mu$};
\draw[->] (0,0) edge (B1);

\node[rectangle] at (2.7+ 1.75,-1.5) [draw,thick,minimum width=0.2cm,minimum height=1.8cm, fill=black] (QC1) {};
\node[rectangle] at (2.7+ 2.25,-1.5) [draw,thick,minimum width=0.2cm,minimum height=1.8cm, fill=black] (QC2) {};
\node[rectangle] at (2.7+ 1.5,-1.5) [draw,thick,minimum width=0.3cm,minimum height=2cm] (Q1) {};
\node[rectangle] at (2.7+ 2,-1.5) [draw,thick,minimum width=0.3cm,minimum height=2cm] (Q2) {};
\node[rectangle] at (2.7+ 2.5,-1.5) [draw,thick,minimum width=0.3cm,minimum height=2cm] (Q3) {};
\node[rectangle] at (Q2.north) {$Q^\mu$};
\draw[->, bend right] (0,0) edge (Q1.west);
\draw[->, bend right] (action) edge (Q1.west);
\node[rectangle] at (2.7+ 4,-1.5) (critic) {$Q^{\mu}(s_t, a_t)$};
\draw[->] (Q3.east) edge (critic.west);
\end{tikzpicture} 
\end{center}
\end{frame}



\section{Questions}
\begin{frame}
\Huge{\centerline{Questions?}}
\end{frame}

%----------------------------------------------------------------------------------------

\end{document}
